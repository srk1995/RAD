05/21/2024 08:47:09 - INFO - __main__ - ***** Running training *****
05/21/2024 08:47:09 - INFO - __main__ -   Num examples = 28000
05/21/2024 08:47:09 - INFO - __main__ -   Num Epochs = 300
05/21/2024 08:47:09 - INFO - __main__ -   Instantaneous batch size per device = 16
05/21/2024 08:47:09 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
05/21/2024 08:47:09 - INFO - __main__ -   Gradient Accumulation steps = 1
05/21/2024 08:47:10 - INFO - __main__ -   Total optimization steps = 525000
05/21/2024 08:47:10 - INFO - __main__ -   Image path = ddpm-model-mattymchen/celeba-hq-64/crop_mult_4_Local-celeba-hq-2000-1000-0-b_bar/FID images
/home/srk1995/anaconda3/envs/ADM/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/srk1995/PycharmProjects/diffusers/src/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `__len__` directly via 'LocalDDPMPipeline' object attribute is deprecated. Please access '__len__' over 'LocalDDPMPipeline's config object instead, e.g. 'scheduler.config.__len__'.
  deprecate("direct config name access", "1.0.0", deprecation_message, standard_warn=False)
