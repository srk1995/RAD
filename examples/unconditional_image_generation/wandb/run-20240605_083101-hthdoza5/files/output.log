06/05/2024 08:31:07 - INFO - __main__ - ***** Running training *****
06/05/2024 08:31:07 - INFO - __main__ -   Num examples = 28000
06/05/2024 08:31:07 - INFO - __main__ -   Num Epochs = 2000
06/05/2024 08:31:07 - INFO - __main__ -   Instantaneous batch size per device = 16
06/05/2024 08:31:07 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
06/05/2024 08:31:08 - INFO - __main__ -   Gradient Accumulation steps = 1
06/05/2024 08:31:08 - INFO - __main__ -   Total optimization steps = 3500000
06/05/2024 08:31:08 - INFO - __main__ -   Image path = ddpm-model-mattymchen/celeba-hq-64/crop_mult_100_Local-celeba-hq-2000-1000-0-b_bar/FID images_590000
06/05/2024 08:31:08 - INFO - accelerate.accelerator - Loading states from ddpm-model-mattymchen/celeba-hq-64/crop_mult_100_Local-celeba-hq-2000-1000-0-b_bar/checkpoint-590000
Resuming from checkpoint checkpoint-590000
06/05/2024 08:31:09 - INFO - accelerate.checkpointing - All model weights loaded successfully
06/05/2024 08:31:10 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
06/05/2024 08:31:10 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
06/05/2024 08:31:10 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully
06/05/2024 08:31:10 - INFO - accelerate.checkpointing - All random states loaded successfully
06/05/2024 08:31:11 - INFO - accelerate.accelerator - Loading in 0 custom states
/home/srk1995/anaconda3/envs/ADM/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]











100%|██████████| 250/250 [00:24<00:00, 10.12it/s]
/home/srk1995/PycharmProjects/diffusers/src/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `__len__` directly via 'LocalDDPMPipeline' object attribute is deprecated. Please access '__len__' over 'LocalDDPMPipeline's config object instead, e.g. 'scheduler.config.__len__'.
  deprecate("direct config name access", "1.0.0", deprecation_message, standard_warn=False)
/home/srk1995/PycharmProjects/diffusers/src/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `__len__` directly via 'LocalDDPMPipeline' object attribute is deprecated. Please access '__len__' over 'LocalDDPMPipeline's config object instead, e.g. 'scheduler.config.__len__'.
